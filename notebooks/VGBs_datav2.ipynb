{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the results for the v2 VGB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing modules\n",
    "\n",
    "import numpy as np\n",
    "import os, sys, re\n",
    "import time\n",
    "import glob\n",
    "import copy\n",
    "\n",
    "from LISAhdf5 import LISAhdf5,ParsUnits\n",
    "import tdi\n",
    "\n",
    "import yaml, pandas, csv\n",
    "\n",
    "import FastGB as FB\n",
    "\n",
    "import LISAConstants as LC\n",
    "import FrequencyArray\n",
    "\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "import corner\n",
    "\n",
    "# from MCMC_multichain import MCcube  as mcmc\n",
    "\n",
    "# import utils\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.style.use(['seaborn-ticks','seaborn-deep'])\n",
    "\n",
    "# %pylab inline\n",
    "\n",
    "mpl.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams[\"figure.figsize\"] = (12,7)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### useful functions and parameters \n",
    "\n",
    "### Some settings\n",
    "plotpal = [\"#4C72B0\", \"#C44E52\", \"#CCB974\", \"#55A868\", \"#8172B2\", \"#64B5CD\"]\n",
    "\n",
    "\n",
    "def GetParams(p, ind):\n",
    "    bet = p.get('EclipticLatitude')[ind]\n",
    "    lam = p.get('EclipticLongitude')[ind]\n",
    "    Amp = p.get(\"Amplitude\")[ind]\n",
    "    f0 = p.get(\"Frequency\")[ind]\n",
    "    fdot = p.get(\"FrequencyDerivative\")[ind]\n",
    "    iota = p.get(\"Inclination\")[ind]\n",
    "    psi = p.get(\"Polarization\")[ind]\n",
    "    phi0 = p.get(\"InitialPhase\")[ind]\n",
    "\n",
    "    return (bet, lam, Amp, f0, fdot, iota, psi, phi0)\n",
    "\n",
    "\n",
    "\n",
    "def MakePrior1Src(f_fctr=1.e-3):\n",
    "    Amp_bnd = [-24.0, -20.0] ### log10 amplitude\n",
    "    #fr_bnd = [1.e-3, 7.e-3]\n",
    "    # fr_bnd = np.array([1.0, 2.0])*f_fctr   ### in Hz\n",
    "#     fr_bnd = np.array([10.06, 10.1])*f_fctr   ### in Hz\n",
    "    fr_bnd = np.array([fr_my_min, fr_my_max])\n",
    "    fdot_bnd = [-20.0, -14.0]  ### log10 fdot\n",
    "    sin_bet_bnd = [-1.0, 1.0]\n",
    "    lam_bnd = [0.0, 2.0*np.pi]\n",
    "#     lam_bnd = [-np.pi, np.pi]\n",
    "    cos_iota_bnd = [-1.0, 1.0]\n",
    "    psi_bnd = [0.0, 2.0*np.pi]\n",
    "    phi0_bnd = [0.0, 2.0*np.pi]\n",
    "\n",
    "    prior = [Amp_bnd, fr_bnd, fdot_bnd, sin_bet_bnd, lam_bnd, cos_iota_bnd, psi_bnd, phi0_bnd]\n",
    "    prior = np.array(prior)\n",
    "    return (prior)\n",
    "\n",
    "\n",
    "def Likelihood(Af, Ef):\n",
    "    ib = Af.kmin\n",
    "    ie = Af.kmin+len(Af) \n",
    "    fr = np.arange(Af.kmin, Af.kmin+len(Af))*df\n",
    "    ### TODO I assume that the frequency range is the same for A and E templates\n",
    "        \n",
    "#     SA = tdi.noisepsd_AE(fr, model='Proposal', includewd=None)\n",
    "    SA = tdi.noisepsd_AE(fr, model='Proposal', includewd=None)\n",
    "    SNR2 = np.sum( np.real(DAf[ib:ie] * np.conjugate(Af.data) + DEf[ib:ie] * np.conjugate(Ef.data))/SA )\n",
    "    hh = np.sum((np.absolute(Af.data)**2 + np.absolute(Ef.data)**2) /SA)\n",
    "    \n",
    "#     print (\"SN\", 4.0*df*SNR2, 4.0*df* hh)\n",
    "\n",
    "    loglik = 4.0*df*( SNR2 - 0.5 * hh )\n",
    "    return (loglik)\n",
    "\n",
    "\n",
    "\n",
    "def LikelihoodFlat(pars):\n",
    "    \n",
    "    ### I presume that pars is of dimention: Nsrc x Npars\n",
    "#     print (\"Test\", np.shape(pars))\n",
    "        \n",
    "    Nsrc = int(len(pars)/Npars) ## number of sources in the model \n",
    "    pars = np.reshape(pars, (Nsrc, Npars))\n",
    "    \n",
    "    for ind in range(Nsrc):\n",
    "        pp = pars[ind, :]\n",
    "        \n",
    "        inPrior = True\n",
    "\n",
    "        for i in range(len(pp)):\n",
    "            if (pp[i] < prior[i,0] or pp[i]>prior[i,1]):\n",
    "                inPrior=False\n",
    "                # print ('didnot pass', i, pp[i], prior[i,:])\n",
    "\n",
    "        if (not inPrior):\n",
    "            return (-np.inf)\n",
    "        else:\n",
    "            \n",
    "            # assume parameters are \n",
    "            ## log10(Amp), fr, log10(fdot), sin(beta), lambda, cos(iota), psi, phi0\n",
    "            l_Amp = pp[0]\n",
    "            mf0 = pp[1]\n",
    "            l_fdot = pp[2]\n",
    "            sin_bet = pp[3]\n",
    "            lam = pp[4]\n",
    "            cos_iota = pp[5]\n",
    "            psi = pp[6]\n",
    "            phi0 = pp[7]\n",
    "\n",
    "            iota = np.arccos(cos_iota)\n",
    "            beta = np.arcsin(sin_bet)\n",
    "            Amp = 10.0**l_Amp\n",
    "            f0 = mf0 \n",
    "            fdot = 10.0**l_fdot\n",
    "\n",
    "            prm = np.array([f0, fdot, beta, lam, Amp, iota, psi, -phi0])\n",
    "#             print ('prm = ', prm)\n",
    "            #### Constructing template\n",
    "            Xf_i, Yf_i, Zf_i = fastGB.onefourier(simulator='synthlisa', params=prm, buffer=None, T=Tobs, dt=del_t, algorithm='Michele', oversample=4)\n",
    "            Xf_i.df = df\n",
    "            if (ind == 0):\n",
    "                Xf = copy.deepcopy(Xf_i)\n",
    "                Xf.df = df\n",
    "                Xf.kmin = Xf_i.kmin\n",
    "                Yf = copy.deepcopy(Yf_i)\n",
    "                Yf.df = df\n",
    "                Yf.kmin = Yf_i.kmin\n",
    "                Zf = copy.deepcopy(Zf_i)\n",
    "                Zf.df = df\n",
    "                Zf.kmin = Zf_i.kmin\n",
    "            else:\n",
    "                Xf = Xf + Xf_i\n",
    "                Yf = Yf + Yf_i\n",
    "                Zf = Zf + Zf_i\n",
    "        \n",
    "#     Af = (Zf[:Nfd] - Xf[:Nfd])/np.sqrt(2.0)\n",
    "#     Ef = (Zf[:Nfd] - 2.0*Yf[:Nfd] + Xf[:Nfd])/np.sqrt(6.0)\n",
    "#     Af = Af/df\n",
    "#     Ef = Ef/df  ### ifft normalization\n",
    "    \n",
    "    Af = FrequencyArray.FrequencyArray( ((Zf[:] - Xf[:])/np.sqrt(2.0))/df, dtype=np.complex128, kmin=Xf.kmin, df=Xf.df)\n",
    "    Ef = FrequencyArray.FrequencyArray( ((Zf[:] - 2.0*Yf[:] + Xf[:])/np.sqrt(6.0))/df, dtype=np.complex128, kmin=Xf.kmin, df=Xf.df)\n",
    "\n",
    "        \n",
    "    ib = Xf.kmin\n",
    "    ie = Xf.kmin+len(Xf) \n",
    "    fr = np.arange(Xf.kmin, Xf.kmin+len(Xf))*df\n",
    "    ### TODO I assume that the frequency range is the same for A and E templates\n",
    "        \n",
    "#     SA = tdi.noisepsd_AE(fr, model='Proposal', includewd=None)\n",
    "    SA = tdi.noisepsd_AE(fr, model='Proposal', includewd=None)\n",
    "    SNR2 = np.sum( np.real(DAf[ib:ie] * np.conjugate(Af.data) + DEf[ib:ie] * np.conjugate(Ef.data))/SA )\n",
    "    hh = np.sum((np.absolute(Af.data)**2 + np.absolute(Ef.data)**2) /SA)\n",
    "    plotIt = False\n",
    "    if plotIt:\n",
    "        fig, ax = plt.subplots(nrows=2, sharex=True) \n",
    "        ax[0].plot(fr, np.abs(DAf[ib:ie]))\n",
    "        ax[0].plot(fr, np.abs(Af.data))\n",
    "        \n",
    "        ax[1].plot(fr, np.abs(DEf[ib:ie]))\n",
    "        ax[1].plot(fr, np.abs(Ef.data))\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "#     print (\"SN\", 4.0*df*SNR2, 4.0*df* hh)\n",
    "\n",
    "    loglik = 4.0*df*( SNR2 - 0.5 * hh )\n",
    "    return (loglik) \n",
    "\n",
    "\n",
    "def GetFDdata(Tobs):\n",
    "    \n",
    "    Nt = int(Tobs/del_t)  \n",
    "    XDt = td[:Nt, 1]\n",
    "    YDt = td[:Nt, 2]\n",
    "    ZDt = td[:Nt, 3]\n",
    "    tm = td[:Nt, 0]\n",
    "    win = utils.Window(tm)\n",
    "\n",
    "\n",
    "    DXf = np.fft.fft(XDt)\n",
    "    DYf = np.fft.fft(YDt)\n",
    "    DZf = np.fft.fft(ZDt)\n",
    "    freqD = np.fft.fftfreq(len(tm), del_t)\n",
    "\n",
    "    Nfd = len(freqD)\n",
    "    Nfd = int(Nfd/2)\n",
    "    freqD = freqD[:Nfd]\n",
    "    ### data\n",
    "#     DXf = DXf[:Nfd] *del_t  \n",
    "\n",
    "    DAf = del_t*(DZf[:Nfd] - DXf[:Nfd])/np.sqrt(2.0)\n",
    "    DEf = del_t*(DXf[:Nfd] - 2.0*DYf[:Nfd] + DZf[:Nfd])/np.sqrt(6.0)\n",
    "    \n",
    "    return (freqD, DAf, DEf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data and transforming to FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FD5 =  LISAhdf5(\"/home/stefan/LDC/Radler/data/LDC1-3_VGB_v2.hdf5\")\n",
    "# FD5 =  LISAhdf5(\"/Users/stas/Projects/LISA/ldc1_evaluation/Data/LDC1-3_VGB_v1.hdf5\")\n",
    "Nsrc = FD5.getSourcesNum()\n",
    "GWs = FD5.getSourcesName()\n",
    "print (\"Found %d GW sources: \" % Nsrc, GWs)\n",
    "### TODO make sure GalBin is there\n",
    "if (GWs[0] != 'GalBinaries'):\n",
    "    raise NotImplementedError\n",
    "p = FD5.getSourceParameters(GWs[0])\n",
    "td = FD5.getPreProcessTDI()\n",
    "del_t = float(p.get(\"Cadence\"))\n",
    "Tobs = float(p.get(\"ObservationDuration\"))\n",
    "\n",
    "p.display()\n",
    "Nsrc = len(p.get('Frequency'))\n",
    "\n",
    "df = 1.0/Tobs\n",
    "XDt = td[:, 1]\n",
    "tm = td[:, 0]\n",
    "win = utils.Window(tm)\n",
    "\n",
    "\n",
    "XDf = np.fft.fft(win*td[:, 1])\n",
    "YDf = np.fft.fft(win*td[:, 2])\n",
    "ZDf = np.fft.fft(win*td[:, 3])\n",
    "freqD = np.fft.fftfreq(len(tm), del_t)\n",
    " \n",
    "Nfd = len(freqD)\n",
    "Nfd = int(Nfd/2)\n",
    "freqD = freqD[:Nfd]  ### we use only positive frequencies\n",
    "Adf = (ZDf[:Nfd] - XDf[:Nfd])/np.sqrt(2.0)\n",
    "Edf = (ZDf[:Nfd] - 2.0*YDf[:Nfd] + XDf[:Nfd])/np.sqrt(6.0)\n",
    "Adf = Adf * del_t\n",
    "Edf = Edf * del_t  ### Due to fft conventions\n",
    "\n",
    "\n",
    "fastGB = FB.FastGB(\"Test\", dt=del_t, Tobs=Tobs, orbit=\"analytic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dictionary of submitted results\n",
    "\n",
    "VGBs = {'GW135962': {'BC':3, 'MM':0, 'BH':2},  \n",
    "        'GW125313': {'BC':6, 'MM':9, 'BH':5},\n",
    "        'GW181324': {'BC':8, 'MM':3, 'BH':1},\n",
    "        'GW166667': {'BC':1, 'MM':7, 'BH':0},\n",
    "        'GW194414': {'BC':5, 'MM':1, 'BH':6},\n",
    "        'GW322061': {'BC':4, 'MM':6, 'BH':7},\n",
    "        'GW351250': {'BC':0, 'MM':5, 'BH':9}, \n",
    "        'GW168350': {'BC':2, 'MM':4, 'BH':8},\n",
    "        'GW622028': {'BC':7, 'MM':2, 'BH':4},\n",
    "        'GW261301': {'BC':9, 'MM':8, 'BH':3}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Barcelona data (from ice-csic-ieec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barc_data = []\n",
    "Barc_data_pnd = []\n",
    "fls = glob.glob('/home/stefan/Repositories/ldc1_evaluation_data/submission/Barcelona/ldc1-3_posteriors_ice-csic-ieec_v2/*.csv')\n",
    "print (fls)\n",
    "\n",
    "# with open(fls[0]) as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     for raw in csv_reader:\n",
    "#         print (raw)\n",
    "#         break\n",
    "\n",
    "### Chains are very long we thin them right away\n",
    "\n",
    "for fl in fls:\n",
    "#     df = pandas.read_csv(fl)\n",
    "#     Barc_data_pnd.append(df)\n",
    "    dat = np.genfromtxt(fl, delimiter=',', names=True)[::100]\n",
    "    Barc_data.append(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fls)\n",
    "np.shape(Barc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = '/home/stefan/Repositories/ldc1_evaluation_data/submission/ETH_LDC1-3_2/'\n",
    "ETH_data = {}\n",
    "for nm in VGBs.keys():\n",
    "    dat = np.genfromtxt(dr+nm+\".csv\", delimiter=',', names=True)[::10]\n",
    "    ETH_data[nm]  = dat\n",
    "    print (np.shape(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = '/home/stefan/Repositories/ldc1_evaluation_data/submission/Stefan_LDC14/'\n",
    "ETH_data2 = {}\n",
    "for nm in VGBs.keys():\n",
    "    dat = np.genfromtxt(dr+nm+\".csv\", delimiter=',', names=True)\n",
    "    ETH_data2[nm]  = dat\n",
    "    print (np.shape(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = '/home/stefan/Repositories/ldc1_evaluation_data/submission/Stefan_LDC14/GW125313_two_signals'\n",
    "ETH_data3 = {}\n",
    "dat = np.genfromtxt(dr+\".csv\", delimiter=',', names=True)\n",
    "ETH_data3  = dat\n",
    "print (np.shape(dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ETH and Barc results (add my later) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acor\n",
    "nm = 'GW125313'\n",
    "\n",
    "dat = ETH_data[nm]\n",
    "print (acor.acor(dat['Frequency']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGBs = {'GW135962': {'BC':3, 'MM':0, 'BH':2},  \n",
    "        'GW125313': {'BC':6, 'MM':9, 'BH':5},\n",
    "        'GW181324': {'BC':8, 'MM':3, 'BH':1},\n",
    "        'GW166667': {'BC':1, 'MM':7, 'BH':0},\n",
    "        'GW194414': {'BC':5, 'MM':1, 'BH':6},\n",
    "        'GW322061': {'BC':4, 'MM':6, 'BH':7},\n",
    "        'GW351250': {'BC':0, 'MM':5, 'BH':9}, \n",
    "        'GW168350': {'BC':2, 'MM':4, 'BH':8},\n",
    "        'GW622028': {'BC':7, 'MM':2, 'BH':4},\n",
    "        'GW261301': {'BC':9, 'MM':8, 'BH':3}}\n",
    "\n",
    "nm = 'GW181324'\n",
    "\n",
    "ind = VGBs[nm]['BC']\n",
    "# lbls = [r'$\\lambda$', r'$\\beta$', 'f(Hz)', r'$\\dot{f}$', r'$\\iota$', r'$A$', r'$\\psi$', r'$\\phi_0$']\n",
    "lbls = [r'$\\lambda$', r'$\\beta$', 'f(Hz)', r'$\\dot{f}$', r'$\\cos{\\iota}$', r'$A$', r'$\\psi$', r'$\\phi_0$']\n",
    "\n",
    "datBc = np.zeros((len(Barc_data[ind]), len(lbls)))\n",
    "datBc[:, 0] = Barc_data[ind]['EclipticLongitude'] + np.pi\n",
    "datBc[:, 1] = Barc_data[ind]['EclipticLatitude']\n",
    "datBc[:, 2] = Barc_data[ind]['Frequency']\n",
    "datBc[:, 3] = np.log10(np.abs(Barc_data[ind]['FrequencyDerivative']))\n",
    "# datBc[:, 4] = np.arccos(np.cos(Barc_data[ind]['Inclination']))\n",
    "datBc[:, 4] = np.cos(Barc_data[ind]['Inclination'])\n",
    "datBc[:, 5] = np.log10(Barc_data[ind]['Amplitude'])\n",
    "datBc[:, 6] = Barc_data[ind]['Polarization']\n",
    "datBc[:, 7] = Barc_data[ind]['InitialPhase']\n",
    "\n",
    "dat = ETH_data[nm]\n",
    "\n",
    "datETH = np.zeros((len(dat), len(lbls)))\n",
    "datETH[:, 0] = dat['EclipticLongitude'] + np.pi\n",
    "datETH[:, 1] = dat['EclipticLatitude']\n",
    "datETH[:, 2] = dat['Frequency']\n",
    "datETH[:, 3] = np.log10(np.abs(dat['FrequencyDerivative']))\n",
    "# datETH[:, 4] = np.arccos(np.cos(dat['Inclination']))\n",
    "datETH[:, 4] = np.cos(dat['Inclination'])\n",
    "datETH[:, 5] = np.log10(dat['Amplitude'])\n",
    "datETH[:, 6] = dat['Polarization']\n",
    "datETH[:, 7] = dat['InitialPhase']\n",
    "\n",
    "# dat = ETH_data2[nm]\n",
    "\n",
    "# datETH2 = np.zeros((len(dat), len(lbls)))\n",
    "# datETH2[:, 0] = dat['EclipticLongitude'] + np.pi\n",
    "# datETH2[:, 1] = dat['EclipticLatitude']\n",
    "# datETH2[:, 2] = dat['Frequency']\n",
    "# datETH2[:, 3] = np.log10(np.abs(dat['FrequencyDerivative']))\n",
    "# # datETH2[:, 4] = np.arccos(np.cos(dat['Inclination']))\n",
    "# datETH2[:, 4] = np.cos(dat['Inclination'])\n",
    "# datETH2[:, 5] = np.log10(dat['Amplitude'])\n",
    "# datETH2[:, 6] = dat['Polarization']\n",
    "# datETH2[:, 7] = dat['InitialPhase']\n",
    "\n",
    "# dat = ETH_data3\n",
    "\n",
    "# datETH3 = np.zeros((len(dat), len(lbls)))\n",
    "# datETH3[:, 0] = dat['EclipticLongitude'] + np.pi\n",
    "# datETH3[:, 1] = dat['EclipticLatitude']\n",
    "# datETH3[:, 2] = dat['Frequency']\n",
    "# datETH3[:, 3] = np.log10(np.abs(dat['FrequencyDerivative']))\n",
    "# # datETH3[:, 4] = np.arccos(np.cos(dat['Inclination']))\n",
    "# datETH3[:, 4] = np.cos(dat['Inclination'])\n",
    "# datETH3[:, 5] = np.log10(dat['Amplitude'])\n",
    "# datETH3[:, 6] = dat['Polarization']\n",
    "# datETH3[:, 7] = dat['InitialPhase']\n",
    "\n",
    "ind_0 = 2\n",
    "bet, lam, Amp, f0, fdot, iota, psi, phi0 = GetParams(p, ind_0)\n",
    "\n",
    "# tr_s = np.array([lam+np.pi, bet, f0, np.log10(fdot), np.arccos(np.cos(iota)), np.log10(Amp), psi, phi0])\n",
    "tr_s = np.array([lam+np.pi, bet, f0, np.log10(fdot), np.cos(iota), np.log10(Amp), psi, phi0])\n",
    "print (\"true params\", tr_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (lbls)\n",
    "# rng = [0.999, 0.999, 0.999, 0.999, (0, np.pi), (-22,-21.4), (0.8, np.pi), (0, 2*np.pi)]\n",
    "rng = [0.999, 0.999, 0.999, 0.999, (0, 1.1), (-22,-21.4), (0.8, np.pi), (0, 2*np.pi)]\n",
    "\n",
    "rng = []\n",
    "for i in range(len(lbls)):\n",
    "    minrange = min(datETH[:,i].min(), datBc[:,i].min())\n",
    "    maxrange = max(datETH[:,i].max(), datBc[:,i].max())\n",
    "    oner = ( minrange, maxrange)\n",
    "    rng.append(oner)\n",
    "\n",
    "\n",
    "# fig1 = corner.corner(datETH,  bins=40,  hist_kwargs={'density':True, 'lw':2},  plot_datapoints=False, labels=lbls,  show_titles=True, \\\n",
    "#                         color='darkslategray', truths= tr_s, truth_color='k', use_math_test=True,\\\n",
    "#                         levels=[0.95], title_kwargs={\"fontsize\": 12})\n",
    "\n",
    "\n",
    "fig1 = corner.corner(datETH,  bins=40,  hist_kwargs={'density':True, 'lw':2},  plot_datapoints=False, fill_contours=False,  labels=lbls,  show_titles=True, \\\n",
    "                        color='orangered', truths= tr_s, truth_color='k', use_math_test=True,\\\n",
    "                        levels=[0.5,0.9], title_kwargs={\"fontsize\": 12})#, range=rng)\n",
    "\n",
    "# corner.corner(datBc,  bins=40,  hist_kwargs={'density':True, 'lw':2}, fig=fig1, plot_datapoints=False, fill_contours=False,  labels=lbls,  show_titles=True, \\\n",
    "#                         color=plotpal[3], truths= tr_s, truth_color='k', use_math_test=True,\\\n",
    "#                         levels=[0.9], title_kwargs={\"fontsize\": 12}, range=rng)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How I sample the data (not a search, seeding at true position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_0 = 0\n",
    "ks = list(VGBs.keys())\n",
    "print ('this is ', ks[ind_0])\n",
    "\n",
    "bet, lam, Amp, f0, fdot, iota, psi, phi0 = GetParams(p, ind_0)\n",
    "# print (f0, Amp, fdot)\n",
    "nm_pars1 = ['log10_Amp', 'fr', 'log10_fdot', 'sin_bet', 'lam', 'cos_iota', 'psi', 'phi0'] \n",
    "Npars = 8\n",
    "x0 = np.array([np.log10(Amp), f0,  np.log10(fdot), np.sin(bet), lam+2.0*np.pi, np.cos(iota), psi, phi0])\n",
    "\n",
    "\n",
    "fr_my_min = f0 - 5.e-6\n",
    "fr_my_max = f0 + 5.e-6\n",
    "prior = MakePrior1Src(f_fctr=1.e-3)\n",
    "\n",
    "frac = 1  ### use 1/frac part of the data\n",
    "Tobs = float(p.get(\"ObservationDuration\"))/frac\n",
    "df = 1.0/Tobs\n",
    "\n",
    "freqD, DAf, DEf = GetFDdata(Tobs)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(12, 8))\n",
    "ax[0].plot(freqD, np.abs(DAf))\n",
    "ax[0].set_xlim([fr_my_min, fr_my_max])\n",
    "ax[0].set_ylim([1.e-18, 5e-17])\n",
    "# ax[0].set_xlim([4.e-5, 2.e-2])\n",
    "\n",
    "ax[0].grid(True)\n",
    "ax[1].plot(freqD, np.abs(DEf))\n",
    "ax[1].set_ylim([1.e-18, 5e-17])\n",
    "ax[1].grid(True)\n",
    "\n",
    "fastGB = FB.FastGB(\"Test\", dt=del_t, Tobs=Tobs, orbit=\"analytic\")\n",
    "\n",
    "\n",
    "prm = np.array([f0, fdot, bet,  lam+2.0*np.pi,  Amp,  iota,  psi, -phi0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare sampler and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "Nchains = 3\n",
    "Nadapt = 1000\n",
    "arg_harm= {'maxoff':8.0}\n",
    "prop_args = {'cov' : None, 'DE_skip': 1000}\n",
    "out_dir = './Results/'\n",
    "Npars = 8\n",
    "\n",
    "chainLength = 500000 ###\n",
    "verbal=True\n",
    "\n",
    "x_init = [x0, x0, x0] ### seeding at true location \n",
    "\n",
    "Ms = mcmc.MultiChain_MCMC(np.array(prior), Nchains, LikelihoodFlat, Nadapt, nm_pars1, 1 )\n",
    "Ms.InitialPoints(x_init)\n",
    "Ms.InitializeProposals([{'SCAM':70., 'DE':50, 'slice':40.}, \\\n",
    "                        {'SCAM':70., 'DE':50., 'slice':40.},\\\n",
    "                        {'SCAM':70., 'DE':50., 'slice':40.}], **prop_args)\n",
    "\n",
    "\n",
    "\n",
    "chains = Ms.runMCMC(chainLength,  verbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chnS = np.array(chains[0].chn[100000::50])\n",
    "chnS = np.concatenate((chnS, np.array(chains[1].chn[100000::50])))\n",
    "chnS = np.concatenate((chnS, np.array(chains[2].chn[100000::50])))\n",
    "\n",
    "print (np.shape(chnS))\n",
    "\n",
    "# plt.plot(chnS[:, 1], '.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = 'GW135962'\n",
    "\n",
    "datSt = np.zeros((len(chnS), len(lbls)))\n",
    "datSt[:,0] = chnS[:,4]-np.pi\n",
    "datSt[:,1] = np.arcsin(chnS[:, 3])\n",
    "datSt[:,2] = chnS[:, 1]\n",
    "datSt[:,3] = chnS[:, 2]\n",
    "# datSt[:,4] = np.pi-np.arccos(chSt[:, 5])\n",
    "datSt[:,4] =chnS[:, 5]\n",
    "datSt[:,5] = chnS[:, 0]\n",
    "datSt[:, 6] = chnS[:, 6]\n",
    "datSt[:, 7] =  chnS[:, 7]\n",
    "\n",
    "ind = VGBs[nm]['BC']\n",
    "# lbls = [r'$\\lambda$', r'$\\beta$', 'f(Hz)', r'$\\dot{f}$', r'$\\iota$', r'$A$', r'$\\psi$', r'$\\phi_0$']\n",
    "lbls = [r'$\\lambda$', r'$\\beta$', 'f(Hz)', r'$\\dot{f}$', r'$\\cos{\\iota}$', r'$A$', r'$\\psi$', r'$\\phi_0$']\n",
    "\n",
    "datBc = np.zeros((len(Barc_data[ind]), len(lbls)))\n",
    "datBc[:, 0] = Barc_data[ind]['EclipticLongitude'] + np.pi\n",
    "datBc[:, 1] = Barc_data[ind]['EclipticLatitude']\n",
    "datBc[:, 2] = Barc_data[ind]['Frequency']\n",
    "datBc[:, 3] = np.log10(np.abs(Barc_data[ind]['FrequencyDerivative']))\n",
    "# datBc[:, 4] = np.arccos(np.cos(Barc_data[ind]['Inclination']))\n",
    "datBc[:, 4] = np.cos(Barc_data[ind]['Inclination'])\n",
    "datBc[:, 5] = np.log10(Barc_data[ind]['Amplitude'])\n",
    "datBc[:, 6] = Barc_data[ind]['Polarization']\n",
    "datBc[:, 7] = Barc_data[ind]['InitialPhase']\n",
    "\n",
    "dat = ETH_data[nm]\n",
    "\n",
    "datETH = np.zeros((len(dat), len(lbls)))\n",
    "datETH[:, 0] = dat['EclipticLongitude'] + np.pi\n",
    "datETH[:, 1] = dat['EclipticLatitude']\n",
    "datETH[:, 2] = dat['Frequency']\n",
    "datETH[:, 3] = np.log10(np.abs(dat['FrequencyDerivative']))\n",
    "# datETH[:, 4] = np.arccos(np.cos(dat['Inclination']))\n",
    "datETH[:, 4] = np.cos(dat['Inclination'])\n",
    "datETH[:, 5] = np.log10(dat['Amplitude'])\n",
    "datETH[:, 6] = dat['Polarization']\n",
    "datETH[:, 7] = dat['InitialPhase']\n",
    "\n",
    "ind_0 = 0\n",
    "bet, lam, Amp, f0, fdot, iota, psi, phi0 = GetParams(p, ind_0)\n",
    "\n",
    "# tr_s = np.array([lam+np.pi, bet, f0, np.log10(fdot), np.arccos(np.cos(iota)), np.log10(Amp), psi, phi0])\n",
    "tr_s = np.array([lam+np.pi, bet, f0, np.log10(fdot), np.cos(iota), np.log10(Amp), psi, phi0])\n",
    "print (\"true params\", tr_s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = [(0.325, 0.42), (0.25, 0.4), ( 1.35962000e-03 -3.0e-9,  1.35962000e-03 + 1.e-9), 0.999, (-1, 1), 0.999, (0., 2*np.pi), (0, 2*np.pi)]\n",
    "# rng = [(0.325, 0.42), (0.25, 0.4), 0.999, (-18,-16.5), (0.1, 1.2), (-22.4, -21.6), (0, 2.0*np.pi), (0, 2.0*np.pi)]\n",
    "\n",
    "fig2 = corner.corner(datSt,  bins=40,  hist_kwargs={'density':True, 'lw':2},  plot_datapoints=False, labels=lbls,  show_titles=True, \\\n",
    "                        color='darkslategray', truths= tr_s, truth_color='k', use_math_test=True,\\\n",
    "                        levels=[0.95], title_kwargs={\"fontsize\": 12}, range = rng)\n",
    "\n",
    "\n",
    "corner.corner(datBc,  bins=40,  hist_kwargs={'density':True, 'lw':2}, fig=fig2, plot_datapoints=False, fill_contours=False,  labels=lbls,  show_titles=True, \\\n",
    "                        color='orangered', truths= tr_s, truth_color='k', use_math_test=True,\\\n",
    "                        levels=[0.9], title_kwargs={\"fontsize\": 12}, range=rng)\n",
    "\n",
    "corner.corner(datETH,  bins=40,  hist_kwargs={'density':True, 'lw':2}, fig=fig2, plot_datapoints=False, fill_contours=False,  labels=lbls,  show_titles=True, \\\n",
    "                        color=plotpal[3], truths= tr_s, truth_color='k', use_math_test=True,\\\n",
    "                        levels=[0.9], title_kwargs={\"fontsize\": 12}, range=rng)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
